{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348dac35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to LangChain and Its API\n",
    "A deep dive into the Python library for composable, LLM-powered applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54467cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview: LangChain Modules\n",
    "- **Core:** Base abstractions for LLM chains, prompts, output parsing, memory, vector stores.\n",
    "- **Splitters:** Utilities for splitting text and documents; important for chunking input for LLMs.\n",
    "- **Community:** Community-contributed integrations and experimental components.\n",
    "- **OpenAI Integrations:** Plug-in support for OpenAI models and embeddings via unified LangChain API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10acbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Core Module (`langchain_core`)\n",
    "**Purpose:** Foundation—defines standard interfaces for models, runnables, prompts, memory, vector stores, and more.\n",
    "\n",
    "**Key Entities:**\n",
    "- `Runnable`: Standard protocol—all chains and components implement this.\n",
    "- `BaseLLM`: LLM interface (prompt in, completion out).\n",
    "- `PromptTemplate`: Parameterized prompt builder.\n",
    "- `StrOutputParser`: Converts LLM output to string.\n",
    "\n",
    "**Usage:** Compose algorithms/agents as interoperable components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19513f4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Minimal Core Example: Prompt + String Parser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What are three uses of AI in {domain}?\")\n",
    "parser = StrOutputParser()# Ready to combine with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da379fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Format prompt and parse output (model integration in next slide)\n",
    "user_input = {\"domain\": \"healthcare\"}\n",
    "prompt_text = prompt.format(**user_input)\n",
    "print(prompt_text)  # --> What are three uses of AI in healthcare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fae584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Splitters Module (`langchain_text_splitters`)\n",
    "**Purpose:** Handles splitting large text/documents into chunks for efficient LLM ingestion/embedding.\n",
    "\n",
    "**Key Entities:**\n",
    "- `CharacterTextSplitter`: Length-based chunking (tokens, chars)\n",
    "- `RecursiveCharacterTextSplitter`: Hierarchical chunking (paragraphs → sentences → words)\n",
    "- `Language`: Enum for programming-language-aware splitting\n",
    "\n",
    "**Usage:** Preprocessing for summarization, semantic search, RAG pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033abaae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Recursive Splitting of Text\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "doc = \"\"\"AI is rapidly evolving.\n",
    "It is widely used in healthcare, finance, and education.\n",
    "Models must be provided with clear, structured input.\"\"\"\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "chunks = splitter.split_text(doc)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fe178",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Community Module (`langchain_community`)\n",
    "**Purpose:** Houses extended and community-contributed integrations such as specialty connectors, retrievers, and tools.\n",
    "\n",
    "**Example Entities:**\n",
    "- Connectors to search engines, databases, niche APIs\n",
    "- Specialized retrievers for advanced search\n",
    "\n",
    "**Usage:** Expand LangChain with community-driven, plug-and-play functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a832d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Community integration example: DuckDuckGo Retriever (as available)\n",
    "# from langchain_community.retrievers import DuckDuckGoRetriever\n",
    "\n",
    "# retriever = DuckDuckGoRetriever()\n",
    "# results = retriever.get_relevant_documents(\"LangChain latest version\")\n",
    "# print(results[:1])  # Show first retrieved document\n",
    "\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchResults\n",
    "\n",
    "ddg = DuckDuckGoSearchResults()\n",
    "results = ddg.invoke(\"LangChain latest version\")\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3772970b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenAI Integrations (`langchain_openai`)\n",
    "**Purpose:** Seamlessly use OpenAI LLMs and embeddings via LangChain’s interface.\n",
    "\n",
    "**Key Classes:**\n",
    "- `OpenAI`: For GPT models, used like any LangChain LLM\n",
    "- `OpenAIEmbeddings`: For embedding generation\n",
    "\n",
    "**Inputs:** Model name, API key, prompt or texts. **Outputs:** LLM completions, embeddings, etc.\n",
    "\n",
    "**Usage:** Unify OpenAI-based chains, retrieval augmentation, generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30ef0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Simple OpenAI Model Invocation via LangChain\n",
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    temperature=0.2\n",
    ")\n",
    "response = llm.invoke(\"Summarize the role of LangChain core module.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb16686",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Using OpenAI Embeddings with LangChain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "embedding = embedder.embed_query(\"LangChain enables composability for LLM apps.\")\n",
    "print(embedding[:5])  # Show first dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0bfdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pulling It Together: A Simple LCEL (LangChain Expression Language) Chain\n",
    "**Example:** Prompt with parameter ⟶ OpenAI model ⟶ Output parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2d8d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt and parser set up earlier\n",
    "my_prompt = PromptTemplate.from_template(\"List 2 impacts of LLMs in {field}.\")\n",
    "my_parser = StrOutputParser()\n",
    "\n",
    "chain = my_prompt | llm | my_parser\n",
    "output = chain.invoke({\"field\": \"education\"})\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "rise": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
