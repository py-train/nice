{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db82f615",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Dive: OpenAI API\n",
    "Explore the key components of OpenAI API with a focus on Embeddings and Chat Completions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff9ffb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## API Parts Overview\n",
    "- **Embeddings:** Vector representations of text enabling semantic search, clustering, similarity.\n",
    "- **Chat Completions:** Conversational AI responses using advanced LLMs like GPT-4o.\n",
    "- **Text completions:** Traditional completion style prompts.\n",
    "- Other features such as image generation, moderation are available but out of scope here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ee037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embeddings\n",
    "## What are Embeddings?\n",
    "Embeddings are dense numerical vector representations of input text (or other data) capturing semantic relationships.\n",
    "Texts with similar meanings produce vectors that are close in vector space.\n",
    "- Used in similarity search, clustering, recommendations, semantic search, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbb473",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OpenAI Embeddings API\n",
    "**Input schema:**\n",
    "- `model`: embedding model name (e.g., `text-embedding-3-small`)\n",
    "- `input`: string or list of strings to embed\n",
    "\n",
    "**Output schema:**\n",
    "- `data`: list of objects containing `embedding` (vector of floats), `index`\n",
    "- `usage`: tokens used information\n",
    "\n",
    "Typical call: `client.embeddings.create(model, input)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a70f8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Embeddings creation example\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "texts = [\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Machine learning models can classify images and text.\"\n",
    "]\n",
    "response = client.embeddings.create(\n",
    "    model='text-embedding-3-small',\n",
    "    input=texts\n",
    ")\n",
    "\n",
    "for i, data in enumerate(response.data):\n",
    "    print(f\"Text: {texts[i]}\")\n",
    "    print(f\"Embedding vector (first 5 dimensions): {data.embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca406a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use Case: Text Summarization with Embeddings + Chat\n",
    "We combine embeddings for document representations and chat completions for generating summaries.\n",
    "1. Compute document embeddings\n",
    "2. Use LLM chat to summarize or answer questions based on embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b62bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"OpenAI provides state-of-the-art language models.\",\n",
    "    \"Embeddings allow semantic search and clustering.\",\n",
    "    \"LangChain helps build chained LLM workflows.\"\n",
    "]\n",
    "\n",
    "# Get embeddings for documents\n",
    "doc_embeddings_resp = client.embeddings.create(model='text-embedding-3-small', input=documents)\n",
    "doc_embeddings = [d.embedding for d in doc_embeddings_resp.data]\n",
    "\n",
    "# Combine embeddings with chat completions (simplified example)\n",
    "query_text = \"What does OpenAI provide?\"\n",
    "\n",
    "# Simple similarity check (cosine) - stub, actual code would implement fully\n",
    "def cosine_sim(vec1, vec2):\n",
    "    import numpy as np\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "query_embedding_resp = client.embeddings.create(model='text-embedding-3-small', input=query_text)\n",
    "query_embedding = query_embedding_resp.data[0].embedding\n",
    "\n",
    "similarities = [cosine_sim(query_embedding, emb) for emb in doc_embeddings]\n",
    "best_doc = documents[similarities.index(max(similarities))]\n",
    "\n",
    "# Use chat completion to summarize the best matching document\n",
    "chat_resp = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following: {best_doc}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(chat_resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa46f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chat Completions\n",
    "## What are Chat Completions?\n",
    "Interactive, multi-turn conversations with language models optimized for chat.\n",
    "Chat-based models understand roles like system, user, assistant.\n",
    "\n",
    "## Schema Overview\n",
    "**Input:**\n",
    "- `model`: model name (e.g., 'gpt-4o')\n",
    "- `messages`: list of dicts with `role` (system/user/assistant) and `content`\n",
    "- Optional parameters: temperature, max tokens, stop sequences.\n",
    "\n",
    "**Output:**\n",
    "- `choices`: list with message outputs containing role and content\n",
    "- `usage`: token usage counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fe51c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Chat Completion example\n",
    "chat_response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the concept of transfer learning in AI.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36529fa0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use Case: Question Answering\n",
    "Leverage chat completions to answer user questions interactively.\n",
    "Built on top of document embeddings + semantic search, or external knowledge sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee7061",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Simple Q&A example leveraging a document context\n",
    "context = \"OpenAI develops advanced AI models like GPT-4 and Codex.\"\n",
    "question = \"What advanced models has OpenAI developed?\"\n",
    "\n",
    "qa_chat = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Answer based on this context: {context} \\n Question: {question}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(qa_chat.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "rise": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
